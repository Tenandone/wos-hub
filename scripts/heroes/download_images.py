import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse

# ==================================================
# ê¸°ë³¸ ì„¤ì •
# ==================================================
GRADE = "ssr"
SEASON = "s15"          # s2, s3 ... ë³€ê²½ ê°€ëŠ¥
HERO_NAME = "viveca"    # ì˜ì›…ëª…

HTML_PATH = f"../isolate/hero_isolate_{GRADE}_{SEASON}_{HERO_NAME}.html"
OUTPUT_HTML = f"../isolate/{GRADE}_{SEASON}_{HERO_NAME}_local.html"
OUTPUT_IMG_DIR = f"../assets/heroes/{GRADE}/{SEASON}/{HERO_NAME}/img"

os.makedirs(OUTPUT_IMG_DIR, exist_ok=True)

# ==================================================
# HTML ë¡œë“œ
# ==================================================
with open(HTML_PATH, "r", encoding="utf-8") as f:
    soup = BeautifulSoup(f, "html.parser")

downloaded = {}

def download_image(url):
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ + ë¡œì»¬ ê²½ë¡œ ì¹˜í™˜"""
    if not url or not url.startswith("http"):
        return url

    parsed = urlparse(url)
    filename = os.path.basename(parsed.path)
    if not filename:
        return url

    save_path = os.path.join(OUTPUT_IMG_DIR, filename)

    if filename not in downloaded:
        print(f"ğŸ“¥ {filename}")
        r = requests.get(url, timeout=15)
        r.raise_for_status()
        with open(save_path, "wb") as f:
            f.write(r.content)
        downloaded[filename] = True

    return os.path.relpath(save_path, os.path.dirname(OUTPUT_HTML)).replace("\\", "/")

# ==================================================
# ìŠ¤í‚¬ ê·¸ë£¹ íŒŒì„œ (Exploration / Expedition)
# ==================================================
def parse_skill_group(container_id):
    skills = []
    container = soup.find(id=container_id)
    if not container:
        return skills

    cards = container.select(".bg-dark.rounded.p-3")

    for card in cards:
        img = card.find("img")
        title = card.find("h5")
        desc = card.find("p")

        if img and img.get("src"):
            img["src"] = download_image(img["src"])

        skills.append({
            "icon": img["src"] if img else "",
            "name": title.get_text(strip=True) if title else "",
            "description": desc.get_text(" ", strip=True) if desc else ""
        })

    return skills

# ==================================================
# SSR ê¸°ë³¸ ìŠ¤í‚¬ íŒŒì‹±
# ==================================================
exploration_skills = parse_skill_group("exploration-skills")
expedition_skills  = parse_skill_group("expedition-skills")

# ==================================================
# í˜ì´ì§€ ì „ì²´ ì´ë¯¸ì§€ ë¡œì»¬í™”
# ==================================================
for img in soup.find_all("img"):
    src = img.get("src")
    if src and src.startswith("http"):
        try:
            img["src"] = download_image(src)
        except Exception:
            print(f"âš  ì´ë¯¸ì§€ ì‹¤íŒ¨: {src}")

# ==================================================
# HTML ì €ì¥
# ==================================================
with open(OUTPUT_HTML, "w", encoding="utf-8") as f:
    f.write(str(soup))

# ==================================================
# ê²°ê³¼ ë¡œê·¸
# ==================================================
print("\nâœ… SSR ê¸°ë³¸í˜• ì˜ì›… ì²˜ë¦¬ ì™„ë£Œ")
print(f"- ì˜ì›…: {HERO_NAME}")
print(f"- Exploration ìŠ¤í‚¬: {len(exploration_skills)}")
print(f"- Expedition ìŠ¤í‚¬ : {len(expedition_skills)}")
print(f"- ì´ë¯¸ì§€ í´ë”     : {OUTPUT_IMG_DIR}")
print(f"- ë¡œì»¬ HTML       : {OUTPUT_HTML}")
